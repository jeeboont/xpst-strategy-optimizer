{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpst-title"
   },
   "source": [
    "# üéØ XPST Strategy Optimizer - Google Colab\n",
    "\n",
    "**High-Performance Trading Strategy Optimization with Parallel Processing**\n",
    "\n",
    "This notebook provides a supercharged optimization engine for XPST (eXtended Pivot SuperTrend) trading strategies.\n",
    "\n",
    "## üöÄ Features:\n",
    "- **‚ö° Multi-core parallel processing** for 10x faster optimization\n",
    "- **üß† 12-25GB RAM** vs 1GB on Streamlit Cloud\n",
    "- **üéØ 3-step progressive optimization** (Core ‚Üí Filters ‚Üí CB/Re-entry)\n",
    "- **üìÅ Automatic cTrader file generation** (.cbotset/.indiset)\n",
    "- **üìä Comprehensive performance analysis**\n",
    "\n",
    "## ‚è±Ô∏è Performance:\n",
    "- **Streamlit Cloud**: 15-30 minutes\n",
    "- **Google Colab Free**: 3-5 minutes  \n",
    "- **Google Colab Pro**: 1-2 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-title"
   },
   "source": [
    "## üì¶ Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-install"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install yfinance pandas numpy plotly scipy scikit-learn requests\n",
    "\n",
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üì¶ Environment Setup Complete\")\n",
    "print(f\"üî• Available CPU cores: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-title"
   },
   "source": [
    "## ‚öôÔ∏è Optimization Configuration\n",
    "\n",
    "**Edit the configuration below to customize your optimization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-params"
   },
   "outputs": [],
   "source": [
    "# üéØ EDIT THESE PARAMETERS FOR YOUR OPTIMIZATION\n",
    "OPTIMIZATION_CONFIG = {\n",
    "    \"asset\": \"BTC-USD\",              # Asset to optimize (BTC-USD, ETH-USD, EURUSD=X, etc.)\n",
    "    \"timeframe\": \"2m\",               # Timeframe (1m, 2m, 5m, 15m, 1h)\n",
    "    \"period\": \"1mo\",                 # Data period (7d, 14d, 1mo, 2mo, 3mo)\n",
    "    \"steps\": [\"step1\", \"step2\"],     # Optimization steps to run\n",
    "    \"risk_percent\": 2.0,             # Risk per trade (%)\n",
    "    \"max_combinations\": 1000,        # Maximum parameter combinations to test\n",
    "    \"use_parallel\": True,            # Enable parallel processing\n",
    "    \"max_workers\": mp.cpu_count(),   # Number of CPU cores to use\n",
    "    \"early_stopping_patience\": 100   # Early stopping patience\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration loaded:\")\n",
    "for key, value in OPTIMIZATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüìù Available optimization steps:\")\n",
    "print(\"  step1: Core Parameters (Pivot Period, ATR Factor, ATR Period)\")\n",
    "print(\"  step2: Filters (XTrend, ADX, EMA)\")\n",
    "print(\"  step3: Circuit Breaker & Re-Entry\")\n",
    "print(\"\\nüí° Tip: Start with just ['step1'] for faster testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "engine-title"
   },
   "source": [
    "## üöÄ High-Performance Optimization Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "engine-backtester"
   },
   "outputs": [],
   "source": [
    "class HighPerformanceBacktester:\n",
    "    \"\"\"\n",
    "    Optimized backtesting engine for Google Colab\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trades = []\n",
    "        self.equity_curve = []\n",
    "        \n",
    "    def backtest_strategy_vectorized(self, data: pd.DataFrame, parameters: Dict) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"\n",
    "        Vectorized backtesting for faster performance\n",
    "        \"\"\"\n",
    "        # Reset state\n",
    "        self.trades = []\n",
    "        balance = 10000\n",
    "        \n",
    "        # Calculate indicators efficiently\n",
    "        df = self._calculate_indicators_vectorized(data.copy(), parameters)\n",
    "        \n",
    "        # Generate signals\n",
    "        signals = self._generate_signals_vectorized(df, parameters)\n",
    "        \n",
    "        # Execute trades\n",
    "        trades = self._execute_trades_vectorized(df, signals, parameters, balance)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self._calculate_metrics_fast(trades, balance)\n",
    "        \n",
    "        return trades, metrics\n",
    "    \n",
    "    def _calculate_indicators_vectorized(self, df: pd.DataFrame, params: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Vectorized indicator calculations\"\"\"\n",
    "        \n",
    "        # ATR calculation\n",
    "        high_low = df['High'] - df['Low']\n",
    "        high_close = np.abs(df['High'] - df['Close'].shift(1))\n",
    "        low_close = np.abs(df['Low'] - df['Close'].shift(1))\n",
    "        \n",
    "        true_range = np.maximum(high_low, np.maximum(high_close, low_close))\n",
    "        df['ATR'] = true_range.rolling(window=params['atr_period']).mean()\n",
    "        \n",
    "        # SuperTrend calculation (vectorized)\n",
    "        atr_factor = params['atr_factor']\n",
    "        hl2 = (df['High'] + df['Low']) / 2\n",
    "        \n",
    "        if params.get('use_prev_atr', False):\n",
    "            atr_values = df['ATR'].shift(1)\n",
    "        else:\n",
    "            atr_values = df['ATR']\n",
    "            \n",
    "        upper_band = hl2 + (atr_factor * atr_values)\n",
    "        lower_band = hl2 - (atr_factor * atr_values)\n",
    "        \n",
    "        # Vectorized SuperTrend\n",
    "        supertrend, trend = self._calculate_supertrend_vectorized(\n",
    "            df['Close'], upper_band, lower_band\n",
    "        )\n",
    "        \n",
    "        df['SuperTrend'] = supertrend\n",
    "        df['Trend'] = trend\n",
    "        \n",
    "        # Add filters if enabled\n",
    "        if params.get('use_adx', False):\n",
    "            df = self._calculate_adx_vectorized(df)\n",
    "        \n",
    "        if params.get('use_ema', False):\n",
    "            df['EMA'] = df['Close'].ewm(span=params.get('ema_period', 50)).mean()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _calculate_supertrend_vectorized(self, close: pd.Series, \n",
    "                                       upper_band: pd.Series, \n",
    "                                       lower_band: pd.Series) -> Tuple[pd.Series, pd.Series]:\n",
    "        \"\"\"Vectorized SuperTrend calculation\"\"\"\n",
    "        \n",
    "        # Initialize arrays\n",
    "        supertrend = np.full(len(close), np.nan)\n",
    "        trend = np.full(len(close), 1, dtype=int)\n",
    "        \n",
    "        # Adjust bands\n",
    "        for i in range(1, len(close)):\n",
    "            # Upper band adjustment\n",
    "            if upper_band.iloc[i] < upper_band.iloc[i-1] or close.iloc[i-1] > upper_band.iloc[i-1]:\n",
    "                upper_band.iloc[i] = upper_band.iloc[i]\n",
    "            else:\n",
    "                upper_band.iloc[i] = upper_band.iloc[i-1]\n",
    "            \n",
    "            # Lower band adjustment  \n",
    "            if lower_band.iloc[i] > lower_band.iloc[i-1] or close.iloc[i-1] < lower_band.iloc[i-1]:\n",
    "                lower_band.iloc[i] = lower_band.iloc[i]\n",
    "            else:\n",
    "                lower_band.iloc[i] = lower_band.iloc[i-1]\n",
    "            \n",
    "            # Trend calculation\n",
    "            if trend[i-1] == 1 and close.iloc[i] <= lower_band.iloc[i]:\n",
    "                trend[i] = -1\n",
    "            elif trend[i-1] == -1 and close.iloc[i] >= upper_band.iloc[i]:\n",
    "                trend[i] = 1\n",
    "            else:\n",
    "                trend[i] = trend[i-1]\n",
    "            \n",
    "            # SuperTrend value\n",
    "            if trend[i] == 1:\n",
    "                supertrend[i] = lower_band.iloc[i]\n",
    "            else:\n",
    "                supertrend[i] = upper_band.iloc[i]\n",
    "        \n",
    "        return pd.Series(supertrend, index=close.index), pd.Series(trend, index=close.index)\n",
    "    \n",
    "    def _calculate_adx_vectorized(self, df: pd.DataFrame, period: int = 14) -> pd.DataFrame:\n",
    "        \"\"\"Vectorized ADX calculation\"\"\"\n",
    "        \n",
    "        # Directional movement\n",
    "        df['HighDiff'] = df['High'].diff()\n",
    "        df['LowDiff'] = -df['Low'].diff()\n",
    "        \n",
    "        df['PlusDM'] = np.where((df['HighDiff'] > df['LowDiff']) & (df['HighDiff'] > 0), \n",
    "                               df['HighDiff'], 0)\n",
    "        df['MinusDM'] = np.where((df['LowDiff'] > df['HighDiff']) & (df['LowDiff'] > 0), \n",
    "                                df['LowDiff'], 0)\n",
    "        \n",
    "        # Smoothed values\n",
    "        df['PlusDM_smooth'] = df['PlusDM'].rolling(window=period).mean()\n",
    "        df['MinusDM_smooth'] = df['MinusDM'].rolling(window=period).mean()\n",
    "        df['ATR_smooth'] = df['ATR'].rolling(window=period).mean()\n",
    "        \n",
    "        # Directional indicators\n",
    "        df['PlusDI'] = 100 * df['PlusDM_smooth'] / df['ATR_smooth']\n",
    "        df['MinusDI'] = 100 * df['MinusDM_smooth'] / df['ATR_smooth']\n",
    "        \n",
    "        # ADX\n",
    "        df['DX'] = 100 * np.abs(df['PlusDI'] - df['MinusDI']) / (df['PlusDI'] + df['MinusDI'])\n",
    "        df['ADX'] = df['DX'].rolling(window=period).mean()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _generate_signals_vectorized(self, df: pd.DataFrame, params: Dict) -> pd.Series:\n",
    "        \"\"\"Vectorized signal generation\"\"\"\n",
    "        \n",
    "        # Base signals from trend changes\n",
    "        trend_change = df['Trend'].diff()\n",
    "        buy_signals = (trend_change == 2)  # -1 to 1\n",
    "        sell_signals = (trend_change == -2)  # 1 to -1\n",
    "        \n",
    "        signals = pd.Series(0, index=df.index)\n",
    "        signals[buy_signals] = 1\n",
    "        signals[sell_signals] = -1\n",
    "        \n",
    "        # Apply filters\n",
    "        if params.get('use_adx', False):\n",
    "            adx_filter = df['ADX'] >= params.get('adx_threshold', 15)\n",
    "            signals = signals * adx_filter\n",
    "        \n",
    "        if params.get('use_ema', False):\n",
    "            ema_filter_long = df['Close'] > df['EMA']\n",
    "            ema_filter_short = df['Close'] < df['EMA']\n",
    "            \n",
    "            signals = np.where((signals == 1) & ~ema_filter_long, 0, signals)\n",
    "            signals = np.where((signals == -1) & ~ema_filter_short, 0, signals)\n",
    "        \n",
    "        return pd.Series(signals, index=df.index)\n",
    "    \n",
    "    def _execute_trades_vectorized(self, df: pd.DataFrame, signals: pd.Series, \n",
    "                                 params: Dict, initial_balance: float) -> List[Dict]:\n",
    "        \"\"\"Vectorized trade execution\"\"\"\n",
    "        \n",
    "        trades = []\n",
    "        signal_indices = signals[signals != 0].index\n",
    "        \n",
    "        if len(signal_indices) == 0:\n",
    "            return trades\n",
    "        \n",
    "        # Calculate position sizes and P&L vectorized\n",
    "        risk_percent = params.get('risk_percent', 2.0) / 100\n",
    "        \n",
    "        for i, signal_time in enumerate(signal_indices[:-1]):\n",
    "            signal = signals[signal_time]\n",
    "            entry_price = df.loc[signal_time, 'Close']\n",
    "            atr = df.loc[signal_time, 'ATR']\n",
    "            \n",
    "            # Find exit\n",
    "            next_signal_time = signal_indices[i + 1]\n",
    "            exit_price = df.loc[next_signal_time, 'Close']\n",
    "            \n",
    "            # Calculate trade\n",
    "            stop_distance = atr * params.get('stop_loss_atr_multiplier', 1.0)\n",
    "            risk_amount = initial_balance * risk_percent\n",
    "            position_size = risk_amount / stop_distance\n",
    "            \n",
    "            if signal == 1:  # Long\n",
    "                pnl = (exit_price - entry_price) * position_size\n",
    "            else:  # Short\n",
    "                pnl = (entry_price - exit_price) * position_size\n",
    "            \n",
    "            trade = {\n",
    "                'entry_time': signal_time,\n",
    "                'exit_time': next_signal_time,\n",
    "                'direction': 'Long' if signal == 1 else 'Short',\n",
    "                'entry_price': entry_price,\n",
    "                'exit_price': exit_price,\n",
    "                'position_size': position_size,\n",
    "                'pnl': pnl,\n",
    "                'pnl_percent': (pnl / initial_balance) * 100\n",
    "            }\n",
    "            \n",
    "            trades.append(trade)\n",
    "        \n",
    "        return trades\n",
    "    \n",
    "    def _calculate_metrics_fast(self, trades: List[Dict], initial_balance: float) -> Dict:\n",
    "        \"\"\"Fast metrics calculation\"\"\"\n",
    "        \n",
    "        if not trades:\n",
    "            return self._empty_metrics()\n",
    "        \n",
    "        trade_df = pd.DataFrame(trades)\n",
    "        \n",
    "        total_trades = len(trade_df)\n",
    "        winning_trades = len(trade_df[trade_df['pnl'] > 0])\n",
    "        \n",
    "        total_pnl = trade_df['pnl'].sum()\n",
    "        total_return = (total_pnl / initial_balance) * 100\n",
    "        win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "        \n",
    "        avg_win = trade_df[trade_df['pnl'] > 0]['pnl'].mean() if winning_trades > 0 else 0\n",
    "        avg_loss = trade_df[trade_df['pnl'] < 0]['pnl'].mean() if (total_trades - winning_trades) > 0 else 0\n",
    "        \n",
    "        profit_factor = abs(avg_win * winning_trades / (avg_loss * (total_trades - winning_trades))) if avg_loss != 0 else float('inf') if winning_trades > 0 else 0\n",
    "        \n",
    "        # Simple drawdown calculation\n",
    "        cumulative_pnl = trade_df['pnl'].cumsum()\n",
    "        peak = cumulative_pnl.expanding().max()\n",
    "        drawdown = ((peak - cumulative_pnl) / (initial_balance + peak)) * 100\n",
    "        max_drawdown = drawdown.max()\n",
    "        \n",
    "        # Sharpe ratio approximation\n",
    "        returns = trade_df['pnl_percent'].values\n",
    "        sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252) if np.std(returns) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_return': round(total_return, 2),\n",
    "            'total_trades': total_trades,\n",
    "            'winning_trades': winning_trades,\n",
    "            'losing_trades': total_trades - winning_trades,\n",
    "            'win_rate': round(win_rate, 2),\n",
    "            'profit_factor': round(profit_factor, 2),\n",
    "            'avg_win': round(avg_win, 2),\n",
    "            'avg_loss': round(avg_loss, 2),\n",
    "            'max_drawdown': round(max_drawdown, 2),\n",
    "            'sharpe_ratio': round(sharpe_ratio, 2),\n",
    "            'final_balance': round(initial_balance + total_pnl, 2),\n",
    "            'largest_win': round(trade_df['pnl'].max(), 2),\n",
    "            'largest_loss': round(trade_df['pnl'].min(), 2),\n",
    "            'expectancy': round((win_rate/100 * avg_win) + ((100-win_rate)/100 * avg_loss), 2)\n",
    "        }\n",
    "    \n",
    "    def _empty_metrics(self) -> Dict:\n",
    "        \"\"\"Empty metrics for failed optimizations\"\"\"\n",
    "        return {\n",
    "            'total_return': 0, 'total_trades': 0, 'winning_trades': 0, 'losing_trades': 0,\n",
    "            'win_rate': 0, 'profit_factor': 0, 'avg_win': 0, 'avg_loss': 0,\n",
    "            'max_drawdown': 0, 'sharpe_ratio': 0, 'final_balance': 10000,\n",
    "            'largest_win': 0, 'largest_loss': 0, 'expectancy': 0\n",
    "        }\n",
    "\n",
    "print(\"üöÄ High-Performance Backtester Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parallel-title"
   },
   "source": [
    "## ‚ö° Parallel Optimization Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "parallel-engine"
   },
   "outputs": [],
   "source": [
    "class ParallelOptimizationEngine:\n",
    "    \"\"\"\n",
    "    Multi-core optimization engine for Google Colab\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = None):\n",
    "        self.max_workers = max_workers or mp.cpu_count()\n",
    "        self.backtester = HighPerformanceBacktester()\n",
    "        \n",
    "    def optimize_step1_parallel(self, data: pd.DataFrame, progress_callback=None) -> List[Dict]:\n",
    "        \"\"\"Step 1: Parallel core parameter optimization\"\"\"\n",
    "        \n",
    "        print(\"üéØ Starting Step 1: Core Parameter Optimization (Parallel)\")\n",
    "        \n",
    "        # Parameter grid\n",
    "        coarse_grid = {\n",
    "            'pivot_period': [3, 5, 7, 9, 12, 15],\n",
    "            'atr_factor': [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n",
    "            'atr_period': [12, 16, 20, 25, 30, 35]\n",
    "        }\n",
    "        \n",
    "        # Generate combinations\n",
    "        combinations = self._generate_combinations(coarse_grid)\n",
    "        print(f\"üìä Testing {len(combinations)} parameter combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, combinations, progress_callback)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"‚úÖ Step 1 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:10]  # Top 10\n",
    "    \n",
    "    def optimize_step2_parallel(self, data: pd.DataFrame, step1_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Step 2: Parallel filter optimization\"\"\"\n",
    "        \n",
    "        print(\"üîç Starting Step 2: Filter Optimization (Parallel)\")\n",
    "        \n",
    "        filter_combinations = []\n",
    "        \n",
    "        # For each top core result, test filter combinations\n",
    "        for core_result in step1_results[:3]:  # Top 3 core results\n",
    "            core_params = core_result['parameters']\n",
    "            \n",
    "            # Generate filter combinations\n",
    "            filter_options = [\n",
    "                {'use_adx': False, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 10, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 20, 'use_ema': False},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 50},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 100},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 200},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': True, 'ema_period': 50},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': True, 'ema_period': 100}\n",
    "            ]\n",
    "            \n",
    "            for filter_option in filter_options:\n",
    "                combined_params = {**core_params, **filter_option}\n",
    "                filter_combinations.append(combined_params)\n",
    "        \n",
    "        print(f\"üìä Testing {len(filter_combinations)} filter combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, filter_combinations)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"‚úÖ Step 2 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:5]  # Top 5\n",
    "    \n",
    "    def optimize_step3_parallel(self, data: pd.DataFrame, step2_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Step 3: Parallel CB & Re-entry optimization\"\"\"\n",
    "        \n",
    "        print(\"‚ö° Starting Step 3: CB & Re-entry Optimization (Parallel)\")\n",
    "        \n",
    "        cb_combinations = []\n",
    "        \n",
    "        # For each top filter result, test CB combinations\n",
    "        for filter_result in step2_results[:3]:  # Top 3 filter results\n",
    "            base_params = filter_result['parameters']\n",
    "            \n",
    "            # CB options\n",
    "            cb_options = [\n",
    "                {'enable_circuit_breaker': False},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.05},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.08},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.10}\n",
    "            ]\n",
    "            \n",
    "            for cb_option in cb_options:\n",
    "                combined_params = {**base_params, **cb_option}\n",
    "                cb_combinations.append(combined_params)\n",
    "        \n",
    "        print(f\"üìä Testing {len(cb_combinations)} CB combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, cb_combinations)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"‚úÖ Step 3 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:3]  # Top 3 final results\n",
    "    \n",
    "    def _generate_combinations(self, param_grid: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate parameter combinations\"\"\"\n",
    "        import itertools\n",
    "        \n",
    "        keys = list(param_grid.keys())\n",
    "        values = list(param_grid.values())\n",
    "        \n",
    "        combinations = []\n",
    "        for combo in itertools.product(*values):\n",
    "            param_dict = dict(zip(keys, combo))\n",
    "            combinations.append(param_dict)\n",
    "        \n",
    "        return combinations\n",
    "    \n",
    "    def _process_combinations_parallel(self, data: pd.DataFrame, \n",
    "                                     combinations: List[Dict], \n",
    "                                     progress_callback=None) -> List[Dict]:\n",
    "        \"\"\"Process combinations in parallel\"\"\"\n",
    "        \n",
    "        # Limit combinations for faster processing\n",
    "        max_combinations = OPTIMIZATION_CONFIG.get('max_combinations', 1000)\n",
    "        if len(combinations) > max_combinations:\n",
    "            combinations = combinations[:max_combinations]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Use ProcessPoolExecutor for true parallelism\n",
    "        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            \n",
    "            # Submit all jobs\n",
    "            future_to_params = {\n",
    "                executor.submit(test_single_combination, data, params): params\n",
    "                for params in combinations\n",
    "            }\n",
    "            \n",
    "            # Collect results\n",
    "            completed = 0\n",
    "            for future in as_completed(future_to_params):\n",
    "                completed += 1\n",
    "                \n",
    "                if progress_callback:\n",
    "                    progress_callback(completed / len(combinations))\n",
    "                \n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in parallel processing: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Progress update\n",
    "                if completed % 50 == 0:\n",
    "                    print(f\"üìà Completed {completed}/{len(combinations)} combinations\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_fitness(self, metrics: Dict) -> float:\n",
    "        \"\"\"Calculate fitness score\"\"\"\n",
    "        \n",
    "        weights = {\n",
    "            'return_weight': 0.30,\n",
    "            'winrate_weight': 0.25,\n",
    "            'profit_factor_weight': 0.25,\n",
    "            'drawdown_penalty': 0.20\n",
    "        }\n",
    "        \n",
    "        total_return = metrics.get('total_return', 0)\n",
    "        win_rate = metrics.get('win_rate', 0)\n",
    "        profit_factor = metrics.get('profit_factor', 1)\n",
    "        max_drawdown = metrics.get('max_drawdown', 100)\n",
    "        total_trades = metrics.get('total_trades', 0)\n",
    "        \n",
    "        # Normalize metrics\n",
    "        normalized_return = min(max(total_return / 50, 0), 1)\n",
    "        normalized_winrate = win_rate / 100\n",
    "        normalized_pf = min(max((profit_factor - 1) / 2, 0), 1)\n",
    "        drawdown_penalty = min(max(max_drawdown / 30, 0), 1)\n",
    "        \n",
    "        # Calculate composite score\n",
    "        fitness = (\n",
    "            weights['return_weight'] * normalized_return +\n",
    "            weights['winrate_weight'] * normalized_winrate +\n",
    "            weights['profit_factor_weight'] * normalized_pf -\n",
    "            weights['drawdown_penalty'] * drawdown_penalty\n",
    "        )\n",
    "        \n",
    "        # Trade count penalties\n",
    "        if total_trades < 5:\n",
    "            fitness *= 0.2\n",
    "        elif total_trades < 10:\n",
    "            fitness *= 0.6\n",
    "        elif total_trades < 15:\n",
    "            fitness *= 0.9\n",
    "        \n",
    "        return max(fitness, 0)\n",
    "\n",
    "# Global function for multiprocessing\n",
    "def test_single_combination(data: pd.DataFrame, parameters: Dict) -> Optional[Dict]:\n",
    "    \"\"\"Test a single parameter combination (for multiprocessing)\"\"\"\n",
    "    try:\n",
    "        # Add default parameters\n",
    "        full_params = {\n",
    "            'pivot_period': parameters.get('pivot_period', 5),\n",
    "            'atr_factor': parameters.get('atr_factor', 1.2),\n",
    "            'atr_period': parameters.get('atr_period', 12),\n",
    "            'use_prev_atr': parameters.get('use_prev_atr', False),\n",
    "            'use_adx': parameters.get('use_adx', False),\n",
    "            'adx_threshold': parameters.get('adx_threshold', 15),\n",
    "            'use_ema': parameters.get('use_ema', False),\n",
    "            'ema_period': parameters.get('ema_period', 50),\n",
    "            'enable_circuit_breaker': parameters.get('enable_circuit_breaker', False),\n",
    "            'circuit_breaker_buffer': parameters.get('circuit_breaker_buffer', 0.08),\n",
    "            'risk_percent': 2.0,\n",
    "            'stop_loss_atr_multiplier': 1.0\n",
    "        }\n",
    "        \n",
    "        # Run backtest\n",
    "        backtester = HighPerformanceBacktester()\n",
    "        trades, metrics = backtester.backtest_strategy_vectorized(data, full_params)\n",
    "        \n",
    "        # Calculate fitness\n",
    "        engine = ParallelOptimizationEngine()\n",
    "        fitness = engine.calculate_fitness(metrics)\n",
    "        \n",
    "        return {\n",
    "            'parameters': parameters.copy(),\n",
    "            'full_parameters': full_params,\n",
    "            'metrics': metrics,\n",
    "            'fitness': fitness,\n",
    "            'trades': trades\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(f\"‚ö° Parallel Optimization Engine Ready ({mp.cpu_count()} cores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-title"
   },
   "source": [
    "## üìä Data Download and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-download"
   },
   "outputs": [],
   "source": [
    "def download_optimization_data(symbol: str, timeframe: str, period: str) -> pd.DataFrame:\n",
    "    \"\"\"Download and prepare data for optimization\"\"\"\n",
    "    \n",
    "    print(f\"üìä Downloading {symbol} data ({timeframe}, {period})\")\n",
    "    \n",
    "    # Timeframe mapping\n",
    "    timeframe_map = {\n",
    "        '1m': '1m', '2m': '2m', '5m': '5m', \n",
    "        '15m': '15m', '1h': '1h', '4h': '1h'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        data = ticker.history(\n",
    "            period=period,\n",
    "            interval=timeframe_map.get(timeframe, '5m'),\n",
    "            auto_adjust=True,\n",
    "            prepost=False\n",
    "        )\n",
    "        \n",
    "        # Handle 4h resampling\n",
    "        if timeframe == '4h' and not data.empty:\n",
    "            data = data.resample('4h').agg({\n",
    "                'Open': 'first',\n",
    "                'High': 'max', \n",
    "                'Low': 'min',\n",
    "                'Close': 'last',\n",
    "                'Volume': 'sum'\n",
    "            }).dropna()\n",
    "        \n",
    "        # Validate data\n",
    "        if len(data) < 100:\n",
    "            raise ValueError(f\"Insufficient data: only {len(data)} bars\")\n",
    "        \n",
    "        # Clean data\n",
    "        data = data.dropna()\n",
    "        \n",
    "        print(f\"‚úÖ Downloaded {len(data)} bars\")\n",
    "        print(f\"üìÖ Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to download {symbol} data: {str(e)}\")\n",
    "\n",
    "print(\"üìä Data download functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-gen-title"
   },
   "source": [
    "## üîß Configuration File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-generators"
   },
   "outputs": [],
   "source": [
    "def generate_cbot_config(optimized_params: Dict, asset: str, timeframe: str) -> Dict:\n",
    "    \"\"\"Generate cBot configuration\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"Chart\": {\n",
    "            \"Symbol\": asset,\n",
    "            \"Period\": timeframe\n",
    "        },\n",
    "        \"Parameters\": {\n",
    "            \"PosSizing\": 1,\n",
    "            \"RiskPercent\": 2.0,\n",
    "            \"RiskDollars\": 50.0,\n",
    "            \"FixedUnits\": 1000.0,\n",
    "            \"OverrideAsset\": 1,\n",
    "            \"FloorToStep\": True,\n",
    "            \"ForceMinSize\": True,\n",
    "            \"MinStopDistance\": 1.0,\n",
    "            \"PivotPeriod\": optimized_params.get('pivot_period', 5),\n",
    "            \"AtrFactor\": optimized_params.get('atr_factor', 1.2),\n",
    "            \"AtrPeriod\": optimized_params.get('atr_period', 12),\n",
    "            \"UsePrevAtr\": optimized_params.get('use_prev_atr', False),\n",
    "            \"UseXTrend\": optimized_params.get('use_xtrend', False),\n",
    "            \"UseXTrendMTF\": optimized_params.get('use_xtrend_mtf', False),\n",
    "            \"XTrendMTFTimeframe\": optimized_params.get('xtrend_mtf_timeframe', 'm5'),\n",
    "            \"UseAdx\": optimized_params.get('use_adx', False),\n",
    "            \"AdxThreshold\": optimized_params.get('adx_threshold', 15),\n",
    "            \"UseEma\": optimized_params.get('use_ema', False),\n",
    "            \"EmaPeriod\": optimized_params.get('ema_period', 50),\n",
    "            \"EnableCircuitBreaker\": optimized_params.get('enable_circuit_breaker', False),\n",
    "            \"CircuitBreakerBuffer\": optimized_params.get('circuit_breaker_buffer', 0.08),\n",
    "            \"AllowReentry\": optimized_params.get('allow_reentry', False),\n",
    "            \"ReentryCooldownBars\": optimized_params.get('reentry_cooldown_bars', 2),\n",
    "            \"ReentryWindowBars\": optimized_params.get('reentry_window_bars', 15),\n",
    "            \"EnableDetailedLogging\": True,\n",
    "            \"LogSignalDetails\": True,\n",
    "            \"ShowStatsTable\": True,\n",
    "            \"ShowEntryExitMarkers\": True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "def generate_indicator_config(optimized_params: Dict, asset: str, timeframe: str) -> Dict:\n",
    "    \"\"\"Generate Indicator configuration\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"Lines\": [\n",
    "            {\n",
    "                \"IsEnabled\": True,\n",
    "                \"LineName\": \"PivotSupertrend\",\n",
    "                \"Color\": \"#FF0000FF\",\n",
    "                \"LineType\": \"Solid\",\n",
    "                \"LineWidth\": 3.0\n",
    "            }\n",
    "        ],\n",
    "        \"Parameters\": {\n",
    "            \"PivotPeriod\": str(optimized_params.get('pivot_period', 5)),\n",
    "            \"AtrFactor\": str(optimized_params.get('atr_factor', 1.2)),\n",
    "            \"AtrPeriod\": str(optimized_params.get('atr_period', 12)),\n",
    "            \"UsePrevAtr\": str(optimized_params.get('use_prev_atr', False)),\n",
    "            \"UseAdx\": str(optimized_params.get('use_adx', False)),\n",
    "            \"AdxThreshold\": str(optimized_params.get('adx_threshold', 15)),\n",
    "            \"UseEma\": str(optimized_params.get('use_ema', False)),\n",
    "            \"EmaPeriod\": str(optimized_params.get('ema_period', 50)),\n",
    "            \"EnableCircuitBreaker\": str(optimized_params.get('enable_circuit_breaker', False)),\n",
    "            \"CircuitBreakerBuffer\": str(optimized_params.get('circuit_breaker_buffer', 0.08))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "print(\"üîß Configuration generators ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "execution-title"
   },
   "source": [
    "## üöÄ Main Optimization Execution\n",
    "\n",
    "**This is where the magic happens! The cell below will run the complete optimization process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main-execution"
   },
   "outputs": [],
   "source": [
    "def run_full_optimization():\n",
    "    \"\"\"Execute the complete 3-step optimization process\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting XPST Strategy Optimization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extract configuration\n",
    "    asset = OPTIMIZATION_CONFIG[\"asset\"]\n",
    "    timeframe = OPTIMIZATION_CONFIG[\"timeframe\"]\n",
    "    period = OPTIMIZATION_CONFIG[\"period\"]\n",
    "    steps = OPTIMIZATION_CONFIG[\"steps\"]\n",
    "    \n",
    "    optimization_results = {\n",
    "        'asset': asset,\n",
    "        'timeframe': timeframe,\n",
    "        'period': period,\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'steps_completed': [],\n",
    "        'final_results': [],\n",
    "        'all_results': {},\n",
    "        'configuration_files': {},\n",
    "        'status': 'running'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Download data\n",
    "        print(f\"üìä Step 0: Data Download\")\n",
    "        data = download_optimization_data(asset, timeframe, period)\n",
    "        \n",
    "        optimization_results['data_stats'] = {\n",
    "            'total_bars': len(data),\n",
    "            'date_range': f\"{data.index[0]} to {data.index[-1]}\",\n",
    "            'timespan_days': (data.index[-1] - data.index[0]).days\n",
    "        }\n",
    "        \n",
    "        # Initialize optimization engine\n",
    "        engine = ParallelOptimizationEngine(max_workers=OPTIMIZATION_CONFIG[\"max_workers\"])\n",
    "        \n",
    "        # Step 1: Core Parameters\n",
    "        if \"step1\" in steps:\n",
    "            print(f\"\\nüéØ Step 1: Core Parameter Optimization\")\n",
    "            step1_results = engine.optimize_step1_parallel(data)\n",
    "            optimization_results['all_results']['step1'] = step1_results\n",
    "            optimization_results['steps_completed'].append('step1')\n",
    "            print(f\"‚úÖ Step 1 completed: {len(step1_results)} results\")\n",
    "        \n",
    "        # Step 2: Filters  \n",
    "        if \"step2\" in steps and \"step1\" in optimization_results['steps_completed']:\n",
    "            print(f\"\\nüîç Step 2: Filter Optimization\")\n",
    "            step2_results = engine.optimize_step2_parallel(data, optimization_results['all_results']['step1'])\n",
    "            optimization_results['all_results']['step2'] = step2_results\n",
    "            optimization_results['steps_completed'].append('step2')\n",
    "            print(f\"‚úÖ Step 2 completed: {len(step2_results)} results\")\n",
    "        \n",
    "        # Step 3: Circuit Breaker & Re-entry\n",
    "        if \"step3\" in steps and \"step2\" in optimization_results['steps_completed']:\n",
    "            print(f\"\\n‚ö° Step 3: Circuit Breaker & Re-entry Optimization\")\n",
    "            step3_results = engine.optimize_step3_parallel(data, optimization_results['all_results']['step2'])\n",
    "            optimization_results['all_results']['step3'] = step3_results\n",
    "            optimization_results['steps_completed'].append('step3')\n",
    "            print(f\"‚úÖ Step 3 completed: {len(step3_results)} results\")\n",
    "        \n",
    "        # Get final results\n",
    "        final_step = optimization_results['steps_completed'][-1]\n",
    "        final_results = optimization_results['all_results'][final_step][:3]  # Top 3\n",
    "        optimization_results['final_results'] = final_results\n",
    "        \n",
    "        # Generate configuration files\n",
    "        print(f\"\\nüìÅ Generating Configuration Files\")\n",
    "        for i, result in enumerate(final_results):\n",
    "            rank = i + 1\n",
    "            params = result['parameters']\n",
    "            \n",
    "            # Generate cBot config\n",
    "            cbot_config = generate_cbot_config(params, asset, timeframe)\n",
    "            cbot_filename = f\"{asset}_{timeframe}_rank{rank}.cbotset\"\n",
    "            optimization_results['configuration_files'][cbot_filename] = cbot_config\n",
    "            \n",
    "            # Generate Indicator config\n",
    "            indicator_config = generate_indicator_config(params, asset, timeframe)\n",
    "            indicator_filename = f\"{asset}_{timeframe}_rank{rank}.indiset\"\n",
    "            optimization_results['configuration_files'][indicator_filename] = indicator_config\n",
    "        \n",
    "        # Mark as completed\n",
    "        optimization_results['status'] = 'completed'\n",
    "        optimization_results['end_time'] = datetime.now().isoformat()\n",
    "        \n",
    "        # Calculate total time\n",
    "        start_time = datetime.fromisoformat(optimization_results['start_time'])\n",
    "        end_time = datetime.fromisoformat(optimization_results['end_time'])\n",
    "        total_time = (end_time - start_time).total_seconds()\n",
    "        optimization_results['total_time_seconds'] = total_time\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"üéâ OPTIMIZATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"‚è±Ô∏è  Total time: {total_time:.1f} seconds\")\n",
    "        print(f\"üèÜ Top result fitness: {final_results[0]['fitness']:.4f}\")\n",
    "        print(f\"üìà Top result return: {final_results[0]['metrics']['total_return']:.2f}%\")\n",
    "        print(f\"üéØ Win rate: {final_results[0]['metrics']['win_rate']:.1f}%\")\n",
    "        print(f\"üìä Total trades: {final_results[0]['metrics']['total_trades']}\")\n",
    "        \n",
    "        return optimization_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        optimization_results['status'] = 'error'\n",
    "        optimization_results['error'] = str(e)\n",
    "        optimization_results['end_time'] = datetime.now().isoformat()\n",
    "        \n",
    "        print(f\"‚ùå Optimization failed: {str(e)}\")\n",
    "        return optimization_results\n",
    "\n",
    "print(\"üéØ Optimization engine ready to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-title"
   },
   "source": [
    "## üìä Results Display and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-display"
   },
   "outputs": [],
   "source": [
    "def display_optimization_results(results: Dict):\n",
    "    \"\"\"Display formatted optimization results\"\"\"\n",
    "    \n",
    "    if results['status'] != 'completed':\n",
    "        print(f\"‚ùå Optimization Status: {results['status']}\")\n",
    "        if 'error' in results:\n",
    "            print(f\"Error: {results['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üèÜ XPST OPTIMIZATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"Asset: {results['asset']}\")\n",
    "    print(f\"Timeframe: {results['timeframe']}\")\n",
    "    print(f\"Data Period: {results['period']}\")\n",
    "    print(f\"Total Bars: {results['data_stats']['total_bars']}\")\n",
    "    print(f\"Steps Completed: {', '.join(results['steps_completed'])}\")\n",
    "    print(f\"Optimization Time: {results['total_time_seconds']:.1f} seconds\")\n",
    "    \n",
    "    # Top 3 Results\n",
    "    print(\"\\nü•á TOP 3 OPTIMIZATION RESULTS:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results['final_results']):\n",
    "        rank = i + 1\n",
    "        metrics = result['metrics']\n",
    "        params = result['parameters']\n",
    "        \n",
    "        print(f\"\\nüèÖ RANK #{rank} (Fitness: {result['fitness']:.4f})\")\n",
    "        print(f\"   üìà Total Return: {metrics['total_return']:.2f}%\")\n",
    "        print(f\"   üéØ Win Rate: {metrics['win_rate']:.1f}%\")\n",
    "        print(f\"   üí∞ Profit Factor: {metrics['profit_factor']:.2f}\")\n",
    "        print(f\"   üìâ Max Drawdown: {metrics['max_drawdown']:.2f}%\")\n",
    "        print(f\"   üìä Total Trades: {metrics['total_trades']}\")\n",
    "        print(f\"   üìê Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "        \n",
    "        print(f\"   ‚öôÔ∏è Parameters:\")\n",
    "        print(f\"      ‚Ä¢ Pivot Period: {params.get('pivot_period', 'N/A')}\")\n",
    "        print(f\"      ‚Ä¢ ATR Factor: {params.get('atr_factor', 'N/A')}\")\n",
    "        print(f\"      ‚Ä¢ ATR Period: {params.get('atr_period', 'N/A')}\")\n",
    "        print(f\"      ‚Ä¢ Use ADX: {params.get('use_adx', False)}\")\n",
    "        if params.get('use_adx', False):\n",
    "            print(f\"      ‚Ä¢ ADX Threshold: {params.get('adx_threshold', 'N/A')}\")\n",
    "        print(f\"      ‚Ä¢ Use EMA: {params.get('use_ema', False)}\")\n",
    "        if params.get('use_ema', False):\n",
    "            print(f\"      ‚Ä¢ EMA Period: {params.get('ema_period', 'N/A')}\")\n",
    "        print(f\"      ‚Ä¢ Circuit Breaker: {params.get('enable_circuit_breaker', False)}\")\n",
    "        if params.get('enable_circuit_breaker', False):\n",
    "            print(f\"      ‚Ä¢ CB Buffer: {params.get('circuit_breaker_buffer', 'N/A'):.2%}\")\n",
    "\n",
    "def export_results_to_files(results: Dict):\n",
    "    \"\"\"Export results to downloadable files\"\"\"\n",
    "    \n",
    "    if results['status'] != 'completed':\n",
    "        print(\"‚ùå Cannot export: Optimization not completed\")\n",
    "        return\n",
    "    \n",
    "    # Create results summary\n",
    "    summary = {\n",
    "        'optimization_summary': {\n",
    "            'asset': results['asset'],\n",
    "            'timeframe': results['timeframe'],\n",
    "            'period': results['period'],\n",
    "            'completion_time': results['end_time'],\n",
    "            'total_time_seconds': results['total_time_seconds'],\n",
    "            'steps_completed': results['steps_completed']\n",
    "        },\n",
    "        'top_results': results['final_results'],\n",
    "        'data_statistics': results['data_stats']\n",
    "    }\n",
    "    \n",
    "    # Save summary JSON\n",
    "    with open('xpst_optimization_results.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    # Save configuration files\n",
    "    for filename, config in results['configuration_files'].items():\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"\\nüìÅ FILES EXPORTED:\")\n",
    "    print(\"   ‚Ä¢ xpst_optimization_results.json - Complete results summary\")\n",
    "    \n",
    "    for filename in results['configuration_files'].keys():\n",
    "        print(f\"   ‚Ä¢ {filename} - cTrader configuration\")\n",
    "    \n",
    "    print(\"\\nüíæ Files are ready for download!\")\n",
    "\n",
    "print(\"üìä Results display functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-title"
   },
   "source": [
    "## üéØ RUN OPTIMIZATION\n",
    "\n",
    "**Execute this cell to start the optimization process with your configured parameters above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-optimization"
   },
   "outputs": [],
   "source": [
    "# üöÄ EXECUTE THE OPTIMIZATION\n",
    "print(\"üöÄ STARTING XPST OPTIMIZATION...\")\n",
    "print(f\"Using {mp.cpu_count()} CPU cores for parallel processing\\n\")\n",
    "\n",
    "# Run the optimization\n",
    "optimization_results = run_full_optimization()\n",
    "\n",
    "# Display results\n",
    "display_optimization_results(optimization_results)\n",
    "\n",
    "# Export files\n",
    "export_results_to_files(optimization_results)\n",
    "\n",
    "print(\"\\nüéâ OPTIMIZATION COMPLETE!\")\n",
    "print(\"üìÅ Check the files panel on the left to download your results\")\n",
    "print(\"üîó Results are ready for integration with Streamlit\")\n",
    "print(\"\\nüìã Next Steps:\")\n",
    "print(\"1. Download the .cbotset and .indiset files\")\n",
    "print(\"2. Import them into cTrader\")\n",
    "print(\"3. Test on demo account first\")\n",
    "print(\"4. Enjoy optimized trading! üéØ\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_type": "standard"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
