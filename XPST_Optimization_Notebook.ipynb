{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpst-title"
   },
   "source": [
    "# 🎯 XPST Strategy Optimizer - Google Colab\n",
    "\n",
    "**High-Performance Trading Strategy Optimization with Parallel Processing**\n",
    "\n",
    "This notebook provides a supercharged optimization engine for XPST (eXtended Pivot SuperTrend) trading strategies.\n",
    "\n",
    "## 🚀 Features:\n",
    "- **⚡ Multi-core parallel processing** for 10x faster optimization\n",
    "- **🧠 12-25GB RAM** vs 1GB on Streamlit Cloud\n",
    "- **🎯 3-step progressive optimization** (Core → Filters → CB/Re-entry)\n",
    "- **📁 Automatic cTrader file generation** (.cbotset/.indiset)\n",
    "- **📊 Comprehensive performance analysis**\n",
    "\n",
    "## ⏱️ Performance:\n",
    "- **Streamlit Cloud**: 15-30 minutes\n",
    "- **Google Colab Free**: 3-5 minutes  \n",
    "- **Google Colab Pro**: 1-2 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-title"
   },
   "source": [
    "## 📦 Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-install"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install yfinance pandas numpy plotly scipy scikit-learn requests\n",
    "\n",
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📦 Environment Setup Complete\")\n",
    "print(f\"🔥 Available CPU cores: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-title"
   },
   "source": [
    "## ⚙️ Optimization Configuration\n",
    "\n",
    "**Edit the configuration below to customize your optimization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-params"
   },
   "outputs": [],
   "source": [
    "# 🎯 EDIT THESE PARAMETERS FOR YOUR OPTIMIZATION\n",
    "OPTIMIZATION_CONFIG = {\n",
    "    \"asset\": \"BTC-USD\",              # Asset to optimize (BTC-USD, ETH-USD, EURUSD=X, etc.)\n",
    "    \"timeframe\": \"2m\",               # Timeframe (1m, 2m, 5m, 15m, 1h)\n",
    "    \"period\": \"1mo\",                 # Data period (7d, 14d, 1mo, 2mo, 3mo)\n",
    "    \"steps\": [\"step1\", \"step2\"],     # Optimization steps to run\n",
    "    \"risk_percent\": 2.0,             # Risk per trade (%)\n",
    "    \"max_combinations\": 1000,        # Maximum parameter combinations to test\n",
    "    \"use_parallel\": True,            # Enable parallel processing\n",
    "    \"max_workers\": mp.cpu_count(),   # Number of CPU cores to use\n",
    "    \"early_stopping_patience\": 100   # Early stopping patience\n",
    "}\n",
    "\n",
    "print(\"⚙️ Configuration loaded:\")\n",
    "for key, value in OPTIMIZATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n📝 Available optimization steps:\")\n",
    "print(\"  step1: Core Parameters (Pivot Period, ATR Factor, ATR Period)\")\n",
    "print(\"  step2: Filters (XTrend, ADX, EMA)\")\n",
    "print(\"  step3: Circuit Breaker & Re-Entry\")\n",
    "print(\"\\n💡 Tip: Start with just ['step1'] for faster testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "engine-title"
   },
   "source": [
    "## 🚀 High-Performance Optimization Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "engine-backtester"
   },
   "outputs": [],
   "source": [
    "class HighPerformanceBacktester:\n",
    "    \"\"\"\n",
    "    Optimized backtesting engine for Google Colab\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trades = []\n",
    "        self.equity_curve = []\n",
    "        \n",
    "    def backtest_strategy_vectorized(self, data: pd.DataFrame, parameters: Dict) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"\n",
    "        Vectorized backtesting for faster performance\n",
    "        \"\"\"\n",
    "        # Reset state\n",
    "        self.trades = []\n",
    "        balance = 10000\n",
    "        \n",
    "        # Calculate indicators efficiently\n",
    "        df = self._calculate_indicators_vectorized(data.copy(), parameters)\n",
    "        \n",
    "        # Generate signals\n",
    "        signals = self._generate_signals_vectorized(df, parameters)\n",
    "        \n",
    "        # Execute trades\n",
    "        trades = self._execute_trades_vectorized(df, signals, parameters, balance)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self._calculate_metrics_fast(trades, balance)\n",
    "        \n",
    "        return trades, metrics\n",
    "    \n",
    "    def _calculate_indicators_vectorized(self, df: pd.DataFrame, params: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Vectorized indicator calculations\"\"\"\n",
    "        \n",
    "        # ATR calculation\n",
    "        high_low = df['High'] - df['Low']\n",
    "        high_close = np.abs(df['High'] - df['Close'].shift(1))\n",
    "        low_close = np.abs(df['Low'] - df['Close'].shift(1))\n",
    "        \n",
    "        true_range = np.maximum(high_low, np.maximum(high_close, low_close))\n",
    "        df['ATR'] = true_range.rolling(window=params['atr_period']).mean()\n",
    "        \n",
    "        # SuperTrend calculation (vectorized)\n",
    "        atr_factor = params['atr_factor']\n",
    "        hl2 = (df['High'] + df['Low']) / 2\n",
    "        \n",
    "        if params.get('use_prev_atr', False):\n",
    "            atr_values = df['ATR'].shift(1)\n",
    "        else:\n",
    "            atr_values = df['ATR']\n",
    "            \n",
    "        upper_band = hl2 + (atr_factor * atr_values)\n",
    "        lower_band = hl2 - (atr_factor * atr_values)\n",
    "        \n",
    "        # Vectorized SuperTrend\n",
    "        supertrend, trend = self._calculate_supertrend_vectorized(\n",
    "            df['Close'], upper_band, lower_band\n",
    "        )\n",
    "        \n",
    "        df['SuperTrend'] = supertrend\n",
    "        df['Trend'] = trend\n",
    "        \n",
    "        # Add filters if enabled\n",
    "        if params.get('use_adx', False):\n",
    "            df = self._calculate_adx_vectorized(df)\n",
    "        \n",
    "        if params.get('use_ema', False):\n",
    "            df['EMA'] = df['Close'].ewm(span=params.get('ema_period', 50)).mean()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _calculate_supertrend_vectorized(self, close: pd.Series, \n",
    "                                       upper_band: pd.Series, \n",
    "                                       lower_band: pd.Series) -> Tuple[pd.Series, pd.Series]:\n",
    "        \"\"\"Vectorized SuperTrend calculation\"\"\"\n",
    "        \n",
    "        # Initialize arrays\n",
    "        supertrend = np.full(len(close), np.nan)\n",
    "        trend = np.full(len(close), 1, dtype=int)\n",
    "        \n",
    "        # Adjust bands\n",
    "        for i in range(1, len(close)):\n",
    "            # Upper band adjustment\n",
    "            if upper_band.iloc[i] < upper_band.iloc[i-1] or close.iloc[i-1] > upper_band.iloc[i-1]:\n",
    "                upper_band.iloc[i] = upper_band.iloc[i]\n",
    "            else:\n",
    "                upper_band.iloc[i] = upper_band.iloc[i-1]\n",
    "            \n",
    "            # Lower band adjustment  \n",
    "            if lower_band.iloc[i] > lower_band.iloc[i-1] or close.iloc[i-1] < lower_band.iloc[i-1]:\n",
    "                lower_band.iloc[i] = lower_band.iloc[i]\n",
    "            else:\n",
    "                lower_band.iloc[i] = lower_band.iloc[i-1]\n",
    "            \n",
    "            # Trend calculation\n",
    "            if trend[i-1] == 1 and close.iloc[i] <= lower_band.iloc[i]:\n",
    "                trend[i] = -1\n",
    "            elif trend[i-1] == -1 and close.iloc[i] >= upper_band.iloc[i]:\n",
    "                trend[i] = 1\n",
    "            else:\n",
    "                trend[i] = trend[i-1]\n",
    "            \n",
    "            # SuperTrend value\n",
    "            if trend[i] == 1:\n",
    "                supertrend[i] = lower_band.iloc[i]\n",
    "            else:\n",
    "                supertrend[i] = upper_band.iloc[i]\n",
    "        \n",
    "        return pd.Series(supertrend, index=close.index), pd.Series(trend, index=close.index)\n",
    "    \n",
    "    def _calculate_adx_vectorized(self, df: pd.DataFrame, period: int = 14) -> pd.DataFrame:\n",
    "        \"\"\"Vectorized ADX calculation\"\"\"\n",
    "        \n",
    "        # Directional movement\n",
    "        df['HighDiff'] = df['High'].diff()\n",
    "        df['LowDiff'] = -df['Low'].diff()\n",
    "        \n",
    "        df['PlusDM'] = np.where((df['HighDiff'] > df['LowDiff']) & (df['HighDiff'] > 0), \n",
    "                               df['HighDiff'], 0)\n",
    "        df['MinusDM'] = np.where((df['LowDiff'] > df['HighDiff']) & (df['LowDiff'] > 0), \n",
    "                                df['LowDiff'], 0)\n",
    "        \n",
    "        # Smoothed values\n",
    "        df['PlusDM_smooth'] = df['PlusDM'].rolling(window=period).mean()\n",
    "        df['MinusDM_smooth'] = df['MinusDM'].rolling(window=period).mean()\n",
    "        df['ATR_smooth'] = df['ATR'].rolling(window=period).mean()\n",
    "        \n",
    "        # Directional indicators\n",
    "        df['PlusDI'] = 100 * df['PlusDM_smooth'] / df['ATR_smooth']\n",
    "        df['MinusDI'] = 100 * df['MinusDM_smooth'] / df['ATR_smooth']\n",
    "        \n",
    "        # ADX\n",
    "        df['DX'] = 100 * np.abs(df['PlusDI'] - df['MinusDI']) / (df['PlusDI'] + df['MinusDI'])\n",
    "        df['ADX'] = df['DX'].rolling(window=period).mean()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _generate_signals_vectorized(self, df: pd.DataFrame, params: Dict) -> pd.Series:\n",
    "        \"\"\"Vectorized signal generation\"\"\"\n",
    "        \n",
    "        # Base signals from trend changes\n",
    "        trend_change = df['Trend'].diff()\n",
    "        buy_signals = (trend_change == 2)  # -1 to 1\n",
    "        sell_signals = (trend_change == -2)  # 1 to -1\n",
    "        \n",
    "        signals = pd.Series(0, index=df.index)\n",
    "        signals[buy_signals] = 1\n",
    "        signals[sell_signals] = -1\n",
    "        \n",
    "        # Apply filters\n",
    "        if params.get('use_adx', False):\n",
    "            adx_filter = df['ADX'] >= params.get('adx_threshold', 15)\n",
    "            signals = signals * adx_filter\n",
    "        \n",
    "        if params.get('use_ema', False):\n",
    "            ema_filter_long = df['Close'] > df['EMA']\n",
    "            ema_filter_short = df['Close'] < df['EMA']\n",
    "            \n",
    "            signals = np.where((signals == 1) & ~ema_filter_long, 0, signals)\n",
    "            signals = np.where((signals == -1) & ~ema_filter_short, 0, signals)\n",
    "        \n",
    "        return pd.Series(signals, index=df.index)\n",
    "    \n",
    "    def _execute_trades_vectorized(self, df: pd.DataFrame, signals: pd.Series, \n",
    "                                 params: Dict, initial_balance: float) -> List[Dict]:\n",
    "        \"\"\"Vectorized trade execution\"\"\"\n",
    "        \n",
    "        trades = []\n",
    "        signal_indices = signals[signals != 0].index\n",
    "        \n",
    "        if len(signal_indices) == 0:\n",
    "            return trades\n",
    "        \n",
    "        # Calculate position sizes and P&L vectorized\n",
    "        risk_percent = params.get('risk_percent', 2.0) / 100\n",
    "        \n",
    "        for i, signal_time in enumerate(signal_indices[:-1]):\n",
    "            signal = signals[signal_time]\n",
    "            entry_price = df.loc[signal_time, 'Close']\n",
    "            atr = df.loc[signal_time, 'ATR']\n",
    "            \n",
    "            # Find exit\n",
    "            next_signal_time = signal_indices[i + 1]\n",
    "            exit_price = df.loc[next_signal_time, 'Close']\n",
    "            \n",
    "            # Calculate trade\n",
    "            stop_distance = atr * params.get('stop_loss_atr_multiplier', 1.0)\n",
    "            risk_amount = initial_balance * risk_percent\n",
    "            position_size = risk_amount / stop_distance\n",
    "            \n",
    "            if signal == 1:  # Long\n",
    "                pnl = (exit_price - entry_price) * position_size\n",
    "            else:  # Short\n",
    "                pnl = (entry_price - exit_price) * position_size\n",
    "            \n",
    "            trade = {\n",
    "                'entry_time': signal_time,\n",
    "                'exit_time': next_signal_time,\n",
    "                'direction': 'Long' if signal == 1 else 'Short',\n",
    "                'entry_price': entry_price,\n",
    "                'exit_price': exit_price,\n",
    "                'position_size': position_size,\n",
    "                'pnl': pnl,\n",
    "                'pnl_percent': (pnl / initial_balance) * 100\n",
    "            }\n",
    "            \n",
    "            trades.append(trade)\n",
    "        \n",
    "        return trades\n",
    "    \n",
    "    def _calculate_metrics_fast(self, trades: List[Dict], initial_balance: float) -> Dict:\n",
    "        \"\"\"Fast metrics calculation\"\"\"\n",
    "        \n",
    "        if not trades:\n",
    "            return self._empty_metrics()\n",
    "        \n",
    "        trade_df = pd.DataFrame(trades)\n",
    "        \n",
    "        total_trades = len(trade_df)\n",
    "        winning_trades = len(trade_df[trade_df['pnl'] > 0])\n",
    "        \n",
    "        total_pnl = trade_df['pnl'].sum()\n",
    "        total_return = (total_pnl / initial_balance) * 100\n",
    "        win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "        \n",
    "        avg_win = trade_df[trade_df['pnl'] > 0]['pnl'].mean() if winning_trades > 0 else 0\n",
    "        avg_loss = trade_df[trade_df['pnl'] < 0]['pnl'].mean() if (total_trades - winning_trades) > 0 else 0\n",
    "        \n",
    "        profit_factor = abs(avg_win * winning_trades / (avg_loss * (total_trades - winning_trades))) if avg_loss != 0 else float('inf') if winning_trades > 0 else 0\n",
    "        \n",
    "        # Simple drawdown calculation\n",
    "        cumulative_pnl = trade_df['pnl'].cumsum()\n",
    "        peak = cumulative_pnl.expanding().max()\n",
    "        drawdown = ((peak - cumulative_pnl) / (initial_balance + peak)) * 100\n",
    "        max_drawdown = drawdown.max()\n",
    "        \n",
    "        # Sharpe ratio approximation\n",
    "        returns = trade_df['pnl_percent'].values\n",
    "        sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252) if np.std(returns) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_return': round(total_return, 2),\n",
    "            'total_trades': total_trades,\n",
    "            'winning_trades': winning_trades,\n",
    "            'losing_trades': total_trades - winning_trades,\n",
    "            'win_rate': round(win_rate, 2),\n",
    "            'profit_factor': round(profit_factor, 2),\n",
    "            'avg_win': round(avg_win, 2),\n",
    "            'avg_loss': round(avg_loss, 2),\n",
    "            'max_drawdown': round(max_drawdown, 2),\n",
    "            'sharpe_ratio': round(sharpe_ratio, 2),\n",
    "            'final_balance': round(initial_balance + total_pnl, 2),\n",
    "            'largest_win': round(trade_df['pnl'].max(), 2),\n",
    "            'largest_loss': round(trade_df['pnl'].min(), 2),\n",
    "            'expectancy': round((win_rate/100 * avg_win) + ((100-win_rate)/100 * avg_loss), 2)\n",
    "        }\n",
    "    \n",
    "    def _empty_metrics(self) -> Dict:\n",
    "        \"\"\"Empty metrics for failed optimizations\"\"\"\n",
    "        return {\n",
    "            'total_return': 0, 'total_trades': 0, 'winning_trades': 0, 'losing_trades': 0,\n",
    "            'win_rate': 0, 'profit_factor': 0, 'avg_win': 0, 'avg_loss': 0,\n",
    "            'max_drawdown': 0, 'sharpe_ratio': 0, 'final_balance': 10000,\n",
    "            'largest_win': 0, 'largest_loss': 0, 'expectancy': 0\n",
    "        }\n",
    "\n",
    "print(\"🚀 High-Performance Backtester Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parallel-title"
   },
   "source": [
    "## ⚡ Parallel Optimization Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "parallel-engine"
   },
   "outputs": [],
   "source": [
    "class ParallelOptimizationEngine:\n",
    "    \"\"\"\n",
    "    Multi-core optimization engine for Google Colab\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = None):\n",
    "        self.max_workers = max_workers or mp.cpu_count()\n",
    "        self.backtester = HighPerformanceBacktester()\n",
    "        \n",
    "    def optimize_step1_parallel(self, data: pd.DataFrame, progress_callback=None) -> List[Dict]:\n",
    "        \"\"\"Step 1: Parallel core parameter optimization\"\"\"\n",
    "        \n",
    "        print(\"🎯 Starting Step 1: Core Parameter Optimization (Parallel)\")\n",
    "        \n",
    "        # Parameter grid\n",
    "        coarse_grid = {\n",
    "            'pivot_period': [3, 5, 7, 9, 12, 15],\n",
    "            'atr_factor': [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n",
    "            'atr_period': [12, 16, 20, 25, 30, 35]\n",
    "        }\n",
    "        \n",
    "        # Generate combinations\n",
    "        combinations = self._generate_combinations(coarse_grid)\n",
    "        print(f\"📊 Testing {len(combinations)} parameter combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, combinations, progress_callback)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"✅ Step 1 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:10]  # Top 10\n",
    "    \n",
    "    def optimize_step2_parallel(self, data: pd.DataFrame, step1_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Step 2: Parallel filter optimization\"\"\"\n",
    "        \n",
    "        print(\"🔍 Starting Step 2: Filter Optimization (Parallel)\")\n",
    "        \n",
    "        filter_combinations = []\n",
    "        \n",
    "        # For each top core result, test filter combinations\n",
    "        for core_result in step1_results[:3]:  # Top 3 core results\n",
    "            core_params = core_result['parameters']\n",
    "            \n",
    "            # Generate filter combinations\n",
    "            filter_options = [\n",
    "                {'use_adx': False, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 10, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': False},\n",
    "                {'use_adx': True, 'adx_threshold': 20, 'use_ema': False},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 50},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 100},\n",
    "                {'use_adx': False, 'use_ema': True, 'ema_period': 200},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': True, 'ema_period': 50},\n",
    "                {'use_adx': True, 'adx_threshold': 15, 'use_ema': True, 'ema_period': 100}\n",
    "            ]\n",
    "            \n",
    "            for filter_option in filter_options:\n",
    "                combined_params = {**core_params, **filter_option}\n",
    "                filter_combinations.append(combined_params)\n",
    "        \n",
    "        print(f\"📊 Testing {len(filter_combinations)} filter combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, filter_combinations)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"✅ Step 2 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:5]  # Top 5\n",
    "    \n",
    "    def optimize_step3_parallel(self, data: pd.DataFrame, step2_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Step 3: Parallel CB & Re-entry optimization\"\"\"\n",
    "        \n",
    "        print(\"⚡ Starting Step 3: CB & Re-entry Optimization (Parallel)\")\n",
    "        \n",
    "        cb_combinations = []\n",
    "        \n",
    "        # For each top filter result, test CB combinations\n",
    "        for filter_result in step2_results[:3]:  # Top 3 filter results\n",
    "            base_params = filter_result['parameters']\n",
    "            \n",
    "            # CB options\n",
    "            cb_options = [\n",
    "                {'enable_circuit_breaker': False},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.05},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.08},\n",
    "                {'enable_circuit_breaker': True, 'circuit_breaker_buffer': 0.10}\n",
    "            ]\n",
    "            \n",
    "            for cb_option in cb_options:\n",
    "                combined_params = {**base_params, **cb_option}\n",
    "                cb_combinations.append(combined_params)\n",
    "        \n",
    "        print(f\"📊 Testing {len(cb_combinations)} CB combinations\")\n",
    "        \n",
    "        # Parallel processing\n",
    "        results = self._process_combinations_parallel(data, cb_combinations)\n",
    "        \n",
    "        # Sort by fitness\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        \n",
    "        print(f\"✅ Step 3 completed. Best fitness: {results[0]['fitness']:.4f}\")\n",
    "        return results[:3]  # Top 3 final results\n",
    "    \n",
    "    def _generate_combinations(self, param_grid: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate parameter combinations\"\"\"\n",
    "        import itertools\n",
    "        \n",
    "        keys = list(param_grid.keys())\n",
    "        values = list(param_grid.values())\n",
    "        \n",
    "        combinations = []\n",
    "        for combo in itertools.product(*values):\n",
    "            param_dict = dict(zip(keys, combo))\n",
    "            combinations.append(param_dict)\n",
    "        \n",
    "        return combinations\n",
    "    \n",
    "    def _process_combinations_parallel(self, data: pd.DataFrame, \n",
    "                                     combinations: List[Dict], \n",
    "                                     progress_callback=None) -> List[Dict]:\n",
    "        \"\"\"Process combinations in parallel\"\"\"\n",
    "        \n",
    "        # Limit combinations for faster processing\n",
    "        max_combinations = OPTIMIZATION_CONFIG.get('max_combinations', 1000)\n",
    "        if len(combinations) > max_combinations:\n",
    "            combinations = combinations[:max_combinations]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Use ProcessPoolExecutor for true parallelism\n",
    "        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            \n",
    "            # Submit all jobs\n",
    "            future_to_params = {\n",
    "                executor.submit(test_single_combination, data, params): params\n",
    "                for params in combinations\n",
    "            }\n",
    "            \n",
    "            # Collect results\n",
    "            completed = 0\n",
    "            for future in as_completed(future_to_params):\n",
    "                completed += 1\n",
    "                \n",
    "                if progress_callback:\n",
    "                    progress_callback(completed / len(combinations))\n",
    "                \n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error in parallel processing: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Progress update\n",
    "                if completed % 50 == 0:\n",
    "                    print(f\"📈 Completed {completed}/{len(combinations)} combinations\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_fitness(self, metrics: Dict) -> float:\n",
    "        \"\"\"Calculate fitness score\"\"\"\n",
    "        \n",
    "        weights = {\n",
    "            'return_weight': 0.30,\n",
    "            'winrate_weight': 0.25,\n",
    "            'profit_factor_weight': 0.25,\n",
    "            'drawdown_penalty': 0.20\n",
    "        }\n",
    "        \n",
    "        total_return = metrics.get('total_return', 0)\n",
    "        win_rate = metrics.get('win_rate', 0)\n",
    "        profit_factor = metrics.get('profit_factor', 1)\n",
    "        max_drawdown = metrics.get('max_drawdown', 100)\n",
    "        total_trades = metrics.get('total_trades', 0)\n",
    "        \n",
    "        # Normalize metrics\n",
    "        normalized_return = min(max(total_return / 50, 0), 1)\n",
    "        normalized_winrate = win_rate / 100\n",
    "        normalized_pf = min(max((profit_factor - 1) / 2, 0), 1)\n",
    "        drawdown_penalty = min(max(max_drawdown / 30, 0), 1)\n",
    "        \n",
    "        # Calculate composite score\n",
    "        fitness = (\n",
    "            weights['return_weight'] * normalized_return +\n",
    "            weights['winrate_weight'] * normalized_winrate +\n",
    "            weights['profit_factor_weight'] * normalized_pf -\n",
    "            weights['drawdown_penalty'] * drawdown_penalty\n",
    "        )\n",
    "        \n",
    "        # Trade count penalties\n",
    "        if total_trades < 5:\n",
    "            fitness *= 0.2\n",
    "        elif total_trades < 10:\n",
    "            fitness *= 0.6\n",
    "        elif total_trades < 15:\n",
    "            fitness *= 0.9\n",
    "        \n",
    "        return max(fitness, 0)\n",
    "\n",
    "# Global function for multiprocessing\n",
    "def test_single_combination(data: pd.DataFrame, parameters: Dict) -> Optional[Dict]:\n",
    "    \"\"\"Test a single parameter combination (for multiprocessing)\"\"\"\n",
    "    try:\n",
    "        # Add default parameters\n",
    "        full_params = {\n",
    "            'pivot_period': parameters.get('pivot_period', 5),\n",
    "            'atr_factor': parameters.get('atr_factor', 1.2),\n",
    "            'atr_period': parameters.get('atr_period', 12),\n",
    "            'use_prev_atr': parameters.get('use_prev_atr', False),\n",
    "            'use_adx': parameters.get('use_adx', False),\n",
    "            'adx_threshold': parameters.get('adx_threshold', 15),\n",
    "            'use_ema': parameters.get('use_ema', False),\n",
    "            'ema_period': parameters.get('ema_period', 50),\n",
    "            'enable_circuit_breaker': parameters.get('enable_circuit_breaker', False),\n",
    "            'circuit_breaker_buffer': parameters.get('circuit_breaker_buffer', 0.08),\n",
    "            'risk_percent': 2.0,\n",
    "            'stop_loss_atr_multiplier': 1.0\n",
    "        }\n",
    "        \n",
    "        # Run backtest\n",
    "        backtester = HighPerformanceBacktester()\n",
    "        trades, metrics = backtester.backtest_strategy_vectorized(data, full_params)\n",
    "        \n",
    "        # Calculate fitness\n",
    "        engine = ParallelOptimizationEngine()\n",
    "        fitness = engine.calculate_fitness(metrics)\n",
    "        \n",
    "        return {\n",
    "            'parameters': parameters.copy(),\n",
    "            'full_parameters': full_params,\n",
    "            'metrics': metrics,\n",
    "            'fitness': fitness,\n",
    "            'trades': trades\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(f\"⚡ Parallel Optimization Engine Ready ({mp.cpu_count()} cores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-title"
   },
   "source": [
    "## 📊 Data Download and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-download"
   },
   "outputs": [],
   "source": [
    "def download_optimization_data(symbol: str, timeframe: str, period: str) -> pd.DataFrame:\n",
    "    \"\"\"Download and prepare data for optimization\"\"\"\n",
    "    \n",
    "    print(f\"📊 Downloading {symbol} data ({timeframe}, {period})\")\n",
    "    \n",
    "    # Timeframe mapping\n",
    "    timeframe_map = {\n",
    "        '1m': '1m', '2m': '2m', '5m': '5m', \n",
    "        '15m': '15m', '1h': '1h', '4h': '1h'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        data = ticker.history(\n",
    "            period=period,\n",
    "            interval=timeframe_map.get(timeframe, '5m'),\n",
    "            auto_adjust=True,\n",
    "            prepost=False\n",
    "        )\n",
    "        \n",
    "        # Handle 4h resampling\n",
    "        if timeframe == '4h' and not data.empty:\n",
    "            data = data.resample('4h').agg({\n",
    "                'Open': 'first',\n",
    "                'High': 'max', \n",
    "                'Low': 'min',\n",
    "                'Close': 'last',\n",
    "                'Volume': 'sum'\n",
    "            }).dropna()\n",
    "        \n",
    "        # Validate data\n",
    "        if len(data) < 100:\n",
    "            raise ValueError(f\"Insufficient data: only {len(data)} bars\")\n",
    "        \n",
    "        # Clean data\n",
    "        data = data.dropna()\n",
    "        \n",
    "        print(f\"✅ Downloaded {len(data)} bars\")\n",
    "        print(f\"📅 Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to download {symbol} data: {str(e)}\")\n",
    "\n",
    "print(\"📊 Data download functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-gen-title"
   },
   "source": [
    "## 🔧 Configuration File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-generators"
   },
   "outputs": [],
   "source": [
    "def generate_cbot_config(optimized_params: Dict, asset: str, timeframe: str) -> Dict:\n",
    "    \"\"\"Generate cBot configuration\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"Chart\": {\n",
    "            \"Symbol\": asset,\n",
    "            \"Period\": timeframe\n",
    "        },\n",
    "        \"Parameters\": {\n",
    "            \"PosSizing\": 1,\n",
    "            \"RiskPercent\": 2.0,\n",
    "            \"RiskDollars\": 50.0,\n",
    "            \"FixedUnits\": 1000.0,\n",
    "            \"OverrideAsset\": 1,\n",
    "            \"FloorToStep\": True,\n",
    "            \"ForceMinSize\": True,\n",
    "            \"MinStopDistance\": 1.0,\n",
    "            \"PivotPeriod\": optimized_params.get('pivot_period', 5),\n",
    "            \"AtrFactor\": optimized_params.get('atr_factor', 1.2),\n",
    "            \"AtrPeriod\": optimized_params.get('atr_period', 12),\n",
    "            \"UsePrevAtr\": optimized_params.get('use_prev_atr', False),\n",
    "            \"UseXTrend\": optimized_params.get('use_xtrend', False),\n",
    "            \"UseXTrendMTF\": optimized_params.get('use_xtrend_mtf', False),\n",
    "            \"XTrendMTFTimeframe\": optimized_params.get('xtrend_mtf_timeframe', 'm5'),\n",
    "            \"UseAdx\": optimized_params.get('use_adx', False),\n",
    "            \"AdxThreshold\": optimized_params.get('adx_threshold', 15),\n",
    "            \"UseEma\": optimized_params.get('use_ema', False),\n",
    "            \"EmaPeriod\": optimized_params.get('ema_period', 50),\n",
    "            \"EnableCircuitBreaker\": optimized_params.get('enable_circuit_breaker', False),\n",
    "            \"CircuitBreakerBuffer\": optimized_params.get('circuit_breaker_buffer', 0.08),\n",
    "            \"AllowReentry\": optimized_params.get('allow_reentry', False),\n",
    "            \"ReentryCooldownBars\": optimized_params.get('reentry_cooldown_bars', 2),\n",
    "            \"ReentryWindowBars\": optimized_params.get('reentry_window_bars', 15),\n",
    "            \"EnableDetailedLogging\": True,\n",
    "            \"LogSignalDetails\": True,\n",
    "            \"ShowStatsTable\": True,\n",
    "            \"ShowEntryExitMarkers\": True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "def generate_indicator_config(optimized_params: Dict, asset: str, timeframe: str) -> Dict:\n",
    "    \"\"\"Generate Indicator configuration\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"Lines\": [\n",
    "            {\n",
    "                \"IsEnabled\": True,\n",
    "                \"LineName\": \"PivotSupertrend\",\n",
    "                \"Color\": \"#FF0000FF\",\n",
    "                \"LineType\": \"Solid\",\n",
    "                \"LineWidth\": 3.0\n",
    "            }\n",
    "        ],\n",
    "        \"Parameters\": {\n",
    "            \"PivotPeriod\": str(optimized_params.get('pivot_period', 5)),\n",
    "            \"AtrFactor\": str(optimized_params.get('atr_factor', 1.2)),\n",
    "            \"AtrPeriod\": str(optimized_params.get('atr_period', 12)),\n",
    "            \"UsePrevAtr\": str(optimized_params.get('use_prev_atr', False)),\n",
    "            \"UseAdx\": str(optimized_params.get('use_adx', False)),\n",
    "            \"AdxThreshold\": str(optimized_params.get('adx_threshold', 15)),\n",
    "            \"UseEma\": str(optimized_params.get('use_ema', False)),\n",
    "            \"EmaPeriod\": str(optimized_params.get('ema_period', 50)),\n",
    "            \"EnableCircuitBreaker\": str(optimized_params.get('enable_circuit_breaker', False)),\n",
    "            \"CircuitBreakerBuffer\": str(optimized_params.get('circuit_breaker_buffer', 0.08))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "print(\"🔧 Configuration generators ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "execution-title"
   },
   "source": [
    "## 🚀 Main Optimization Execution\n",
    "\n",
    "**This is where the magic happens! The cell below will run the complete optimization process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main-execution"
   },
   "outputs": [],
   "source": [
    "def run_full_optimization():\n",
    "    \"\"\"Execute the complete 3-step optimization process\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting XPST Strategy Optimization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extract configuration\n",
    "    asset = OPTIMIZATION_CONFIG[\"asset\"]\n",
    "    timeframe = OPTIMIZATION_CONFIG[\"timeframe\"]\n",
    "    period = OPTIMIZATION_CONFIG[\"period\"]\n",
    "    steps = OPTIMIZATION_CONFIG[\"steps\"]\n",
    "    \n",
    "    optimization_results = {\n",
    "        'asset': asset,\n",
    "        'timeframe': timeframe,\n",
    "        'period': period,\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'steps_completed': [],\n",
    "        'final_results': [],\n",
    "        'all_results': {},\n",
    "        'configuration_files': {},\n",
    "        'status': 'running'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Download data\n",
    "        print(f\"📊 Step 0: Data Download\")\n",
    "        data = download_optimization_data(asset, timeframe, period)\n",
    "        \n",
    "        optimization_results['data_stats'] = {\n",
    "            'total_bars': len(data),\n",
    "            'date_range': f\"{data.index[0]} to {data.index[-1]}\",\n",
    "            'timespan_days': (data.index[-1] - data.index[0]).days\n",
    "        }\n",
    "        \n",
    "        # Initialize optimization engine\n",
    "        engine = ParallelOptimizationEngine(max_workers=OPTIMIZATION_CONFIG[\"max_workers\"])\n",
    "        \n",
    "        # Step 1: Core Parameters\n",
    "        if \"step1\" in steps:\n",
    "            print(f\"\\n🎯 Step 1: Core Parameter Optimization\")\n",
    "            step1_results = engine.optimize_step1_parallel(data)\n",
    "            optimization_results['all_results']['step1'] = step1_results\n",
    "            optimization_results['steps_completed'].append('step1')\n",
    "            print(f\"✅ Step 1 completed: {len(step1_results)} results\")\n",
    "        \n",
    "        # Step 2: Filters  \n",
    "        if \"step2\" in steps and \"step1\" in optimization_results['steps_completed']:\n",
    "            print(f\"\\n🔍 Step 2: Filter Optimization\")\n",
    "            step2_results = engine.optimize_step2_parallel(data, optimization_results['all_results']['step1'])\n",
    "            optimization_results['all_results']['step2'] = step2_results\n",
    "            optimization_results['steps_completed'].append('step2')\n",
    "            print(f\"✅ Step 2 completed: {len(step2_results)} results\")\n",
    "        \n",
    "        # Step 3: Circuit Breaker & Re-entry\n",
    "        if \"step3\" in steps and \"step2\" in optimization_results['steps_completed']:\n",
    "            print(f\"\\n⚡ Step 3: Circuit Breaker & Re-entry Optimization\")\n",
    "            step3_results = engine.optimize_step3_parallel(data, optimization_results['all_results']['step2'])\n",
    "            optimization_results['all_results']['step3'] = step3_results\n",
    "            optimization_results['steps_completed'].append('step3')\n",
    "            print(f\"✅ Step 3 completed: {len(step3_results)} results\")\n",
    "        \n",
    "        # Get final results\n",
    "        final_step = optimization_results['steps_completed'][-1]\n",
    "        final_results = optimization_results['all_results'][final_step][:3]  # Top 3\n",
    "        optimization_results['final_results'] = final_results\n",
    "        \n",
    "        # Generate configuration files\n",
    "        print(f\"\\n📁 Generating Configuration Files\")\n",
    "        for i, result in enumerate(final_results):\n",
    "            rank = i + 1\n",
    "            params = result['parameters']\n",
    "            \n",
    "            # Generate cBot config\n",
    "            cbot_config = generate_cbot_config(params, asset, timeframe)\n",
    "            cbot_filename = f\"{asset}_{timeframe}_rank{rank}.cbotset\"\n",
    "            optimization_results['configuration_files'][cbot_filename] = cbot_config\n",
    "            \n",
    "            # Generate Indicator config\n",
    "            indicator_config = generate_indicator_config(params, asset, timeframe)\n",
    "            indicator_filename = f\"{asset}_{timeframe}_rank{rank}.indiset\"\n",
    "            optimization_results['configuration_files'][indicator_filename] = indicator_config\n",
    "        \n",
    "        # Mark as completed\n",
    "        optimization_results['status'] = 'completed'\n",
    "        optimization_results['end_time'] = datetime.now().isoformat()\n",
    "        \n",
    "        # Calculate total time\n",
    "        start_time = datetime.fromisoformat(optimization_results['start_time'])\n",
    "        end_time = datetime.fromisoformat(optimization_results['end_time'])\n",
    "        total_time = (end_time - start_time).total_seconds()\n",
    "        optimization_results['total_time_seconds'] = total_time\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"🎉 OPTIMIZATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"⏱️  Total time: {total_time:.1f} seconds\")\n",
    "        print(f\"🏆 Top result fitness: {final_results[0]['fitness']:.4f}\")\n",
    "        print(f\"📈 Top result return: {final_results[0]['metrics']['total_return']:.2f}%\")\n",
    "        print(f\"🎯 Win rate: {final_results[0]['metrics']['win_rate']:.1f}%\")\n",
    "        print(f\"📊 Total trades: {final_results[0]['metrics']['total_trades']}\")\n",
    "        \n",
    "        return optimization_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        optimization_results['status'] = 'error'\n",
    "        optimization_results['error'] = str(e)\n",
    "        optimization_results['end_time'] = datetime.now().isoformat()\n",
    "        \n",
    "        print(f\"❌ Optimization failed: {str(e)}\")\n",
    "        return optimization_results\n",
    "\n",
    "print(\"🎯 Optimization engine ready to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-title"
   },
   "source": [
    "## 📊 Results Display and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-display"
   },
   "outputs": [],
   "source": [
    "def display_optimization_results(results: Dict):\n",
    "    \"\"\"Display formatted optimization results\"\"\"\n",
    "    \n",
    "    if results['status'] != 'completed':\n",
    "        print(f\"❌ Optimization Status: {results['status']}\")\n",
    "        if 'error' in results:\n",
    "            print(f\"Error: {results['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🏆 XPST OPTIMIZATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"Asset: {results['asset']}\")\n",
    "    print(f\"Timeframe: {results['timeframe']}\")\n",
    "    print(f\"Data Period: {results['period']}\")\n",
    "    print(f\"Total Bars: {results['data_stats']['total_bars']}\")\n",
    "    print(f\"Steps Completed: {', '.join(results['steps_completed'])}\")\n",
    "    print(f\"Optimization Time: {results['total_time_seconds']:.1f} seconds\")\n",
    "    \n",
    "    # Top 3 Results\n",
    "    print(\"\\n🥇 TOP 3 OPTIMIZATION RESULTS:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results['final_results']):\n",
    "        rank = i + 1\n",
    "        metrics = result['metrics']\n",
    "        params = result['parameters']\n",
    "        \n",
    "        print(f\"\\n🏅 RANK #{rank} (Fitness: {result['fitness']:.4f})\")\n",
    "        print(f\"   📈 Total Return: {metrics['total_return']:.2f}%\")\n",
    "        print(f\"   🎯 Win Rate: {metrics['win_rate']:.1f}%\")\n",
    "        print(f\"   💰 Profit Factor: {metrics['profit_factor']:.2f}\")\n",
    "        print(f\"   📉 Max Drawdown: {metrics['max_drawdown']:.2f}%\")\n",
    "        print(f\"   📊 Total Trades: {metrics['total_trades']}\")\n",
    "        print(f\"   📐 Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "        \n",
    "        print(f\"   ⚙️ Parameters:\")\n",
    "        print(f\"      • Pivot Period: {params.get('pivot_period', 'N/A')}\")\n",
    "        print(f\"      • ATR Factor: {params.get('atr_factor', 'N/A')}\")\n",
    "        print(f\"      • ATR Period: {params.get('atr_period', 'N/A')}\")\n",
    "        print(f\"      • Use ADX: {params.get('use_adx', False)}\")\n",
    "        if params.get('use_adx', False):\n",
    "            print(f\"      • ADX Threshold: {params.get('adx_threshold', 'N/A')}\")\n",
    "        print(f\"      • Use EMA: {params.get('use_ema', False)}\")\n",
    "        if params.get('use_ema', False):\n",
    "            print(f\"      • EMA Period: {params.get('ema_period', 'N/A')}\")\n",
    "        print(f\"      • Circuit Breaker: {params.get('enable_circuit_breaker', False)}\")\n",
    "        if params.get('enable_circuit_breaker', False):\n",
    "            print(f\"      • CB Buffer: {params.get('circuit_breaker_buffer', 'N/A'):.2%}\")\n",
    "\n",
    "def export_results_to_files(results: Dict):\n",
    "    \"\"\"Export results to downloadable files\"\"\"\n",
    "    \n",
    "    if results['status'] != 'completed':\n",
    "        print(\"❌ Cannot export: Optimization not completed\")\n",
    "        return\n",
    "    \n",
    "    # Create results summary\n",
    "    summary = {\n",
    "        'optimization_summary': {\n",
    "            'asset': results['asset'],\n",
    "            'timeframe': results['timeframe'],\n",
    "            'period': results['period'],\n",
    "            'completion_time': results['end_time'],\n",
    "            'total_time_seconds': results['total_time_seconds'],\n",
    "            'steps_completed': results['steps_completed']\n",
    "        },\n",
    "        'top_results': results['final_results'],\n",
    "        'data_statistics': results['data_stats']\n",
    "    }\n",
    "    \n",
    "    # Save summary JSON\n",
    "    with open('xpst_optimization_results.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    # Save configuration files\n",
    "    for filename, config in results['configuration_files'].items():\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"\\n📁 FILES EXPORTED:\")\n",
    "    print(\"   • xpst_optimization_results.json - Complete results summary\")\n",
    "    \n",
    "    for filename in results['configuration_files'].keys():\n",
    "        print(f\"   • {filename} - cTrader configuration\")\n",
    "    \n",
    "    print(\"\\n💾 Files are ready for download!\")\n",
    "\n",
    "print(\"📊 Results display functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-title"
   },
   "source": [
    "## 🎯 RUN OPTIMIZATION\n",
    "\n",
    "**Execute this cell to start the optimization process with your configured parameters above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-optimization"
   },
   "outputs": [],
   "source": [
    "# 🚀 EXECUTE THE OPTIMIZATION\n",
    "print(\"🚀 STARTING XPST OPTIMIZATION...\")\n",
    "print(f\"Using {mp.cpu_count()} CPU cores for parallel processing\\n\")\n",
    "\n",
    "# Run the optimization\n",
    "optimization_results = run_full_optimization()\n",
    "\n",
    "# Display results\n",
    "display_optimization_results(optimization_results)\n",
    "\n",
    "# Export files\n",
    "export_results_to_files(optimization_results)\n",
    "\n",
    "print(\"\\n🎉 OPTIMIZATION COMPLETE!\")\n",
    "print(\"📁 Check the files panel on the left to download your results\")\n",
    "print(\"🔗 Results are ready for integration with Streamlit\")\n",
    "print(\"\\n📋 Next Steps:\")\n",
    "print(\"1. Download the .cbotset and .indiset files\")\n",
    "print(\"2. Import them into cTrader\")\n",
    "print(\"3. Test on demo account first\")\n",
    "print(\"4. Enjoy optimized trading! 🎯\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_type": "standard"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
